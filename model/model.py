# -*- coding: utf-8 -*-
"""stats201 project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YNGPe0j-8sLiJF1rkD1tohj4GrK1mQI4
"""

"""Data append & merge"""

import pandas as pd

cs_path = "/content/nyu_cs_faculty_scored.csv"
art_path = "/content/nyu_art_faculty_scored.csv"

cs = pd.read_csv(cs_path)
art = pd.read_csv(art_path)

cs["dept"] = "Computer Science"
art["dept"] = "Art"
cs["school"] = "NYU"
art["school"] = "NYU"

combined = pd.concat([cs, art], axis=0, ignore_index=True, sort=False)

out_path = "/content/nyu_cs_art_faculty_scored.csv"
combined.to_csv(out_path, index=False, encoding="utf-8-sig")

print("Saved:", out_path)
print("Rows:", combined.shape[0], "Cols:", combined.shape[1])

import pandas as pd
import re

df1 = pd.read_csv("rmp_ucla_nyu_professors.csv")
df2 = pd.read_csv("nyu_cs_art_faculty_scored.csv")

def norm_name(x):
    if pd.isna(x):
        return ""
    x = str(x).strip().lower()
    x = re.sub(r"[^\w\s]", " ", x)
    x = re.sub(r"\s+", " ", x).strip()
    return x

df1["_key"] = df1["professor"].map(norm_name)
df2["_key"] = df2["name"].map(norm_name)

last3_cols = [c for c in df1.columns if c not in ["_key"]][-3:]
df1_small = df1[["professor"] + last3_cols + ["_key"]].copy()

merged = df2.merge(df1_small, on="_key", how="inner").drop(columns=["_key"])
merged.to_csv("table2_matched_with_table1_last3.csv", index=False, encoding="utf-8-sig")


import pandas as pd

cs_path = "/content/ucla_samueli_cs_faculty_scored.csv"
art_path = "/content/ucla_arts_predictions.csv"

cs = pd.read_csv(cs_path)
art = pd.read_csv(art_path)

cs["dept"] = "Computer Science"
art["dept"] = "Art"
cs["school"] = "UCLA"
art["school"] = "UCLA"

combined = pd.concat([cs, art], axis=0, ignore_index=True, sort=False)

out_path = "/content/ucla_cs_art_faculty_scored.csv"
combined.to_csv(out_path, index=False, encoding="utf-8-sig")

print("Saved:", out_path)
print("Rows:", combined.shape[0], "Cols:", combined.shape[1])

import pandas as pd
import re

df1 = pd.read_csv("rmp_ucla_nyu_professors.csv")
df2 = pd.read_csv("ucla_cs_art_faculty_scored.csv")

def norm_name(x):
    if pd.isna(x):
        return ""
    x = str(x).strip().lower()
    x = re.sub(r"[^\w\s]", " ", x)
    x = re.sub(r"\s+", " ", x).strip()
    return x

df1["_key"] = df1["professor"].map(norm_name)
df2["_key"] = df2["name"].map(norm_name)

last3_cols = [c for c in df1.columns if c not in ["_key"]][-3:]
df1_small = df1[["professor"] + last3_cols + ["_key"]].copy()

merged = df2.merge(df1_small, on="_key", how="inner").drop(columns=["_key"])
merged.to_csv("table4_matched_with_table3_last3.csv", index=False, encoding="utf-8-sig")

import pandas as pd

p1 = "/content/table2_matched_with_table1_last3.csv"
p2 = "/content/table4_matched_with_table3_last3.csv"

df1 = pd.read_csv(p1)
df2 = pd.read_csv(p2)

all_cols = sorted(set(df1.columns).union(set(df2.columns)))
df1 = df1.reindex(columns=all_cols)
df2 = df2.reindex(columns=all_cols)

df = pd.concat([df1, df2], ignore_index=True)

out_path = "/content/training_dataset_appended_clean.csv"
df.to_csv(out_path, index=False, encoding="utf-8-sig")

"""week3 baseline model training"""

import pandas as pd
from sklearn.model_selection import KFold, cross_validate
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.dummy import DummyRegressor
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.ensemble import HistGradientBoostingRegressor

df = pd.read_csv("/content/training_dataset_appended_clean.csv")

mask_invalid = (df["avg_rating"] == 0) ｜ (df["avg_difficulty"] == 0) ｜ (df["would_take_again_percent"] == -1)
df = df.loc[~mask_invalid].copy()

df = df.dropna(subset=["avg_rating", "pred_score_raw"]).copy()

y = df["avg_rating"].astype(float)

num_features = ["pred_score_raw"]
cat_features = ["dept", "school"] 

X = df[num_features + cat_features].copy()

numeric_pipe = Pipeline([
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler()),
])

categorical_pipe = Pipeline([
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("onehot", OneHotEncoder(handle_unknown="ignore")),
])

preprocess = ColumnTransformer([
    ("num", numeric_pipe, num_features),
    ("cat", categorical_pipe, cat_features),
], remainder="drop")

models = {
    "DummyMean": DummyRegressor(strategy="mean"),
    "LinearRegression": LinearRegression(),
    "Ridge(alpha=1.0)": Ridge(alpha=1.0, random_state=0),
    "HistGBR": HistGradientBoostingRegressor(random_state=0),
}

cv = KFold(n_splits=5, shuffle=True, random_state=0)
scoring = {
    "MAE": "neg_mean_absolute_error",
    "RMSE": "neg_root_mean_squared_error",
    "R2": "r2",
}

rows = []
for name, model in models.items():
    pipe = Pipeline([("preprocess", preprocess), ("model", model)])
    out = cross_validate(pipe, X, y, cv=cv, scoring=scoring)
    rows.append({
        "model": name,
        "n": len(y),
        "MAE(mean)": -out["test_MAE"].mean(),
        "RMSE(mean)": -out["test_RMSE"].mean(),
        "R2(mean)": out["test_R2"].mean(),
    })
    

res = pd.DataFrame(rows).sort_values("MAE(mean)")
print("Invalid removed:", int(mask_invalid.sum()))
print(res.to_string(index=False))

"""week3 baseline model visualization"""

import os
import matplotlib.pyplot as plt

out_dir = "/content/drive/MyDrive/plots"
os.makedirs(out_dir, exist_ok=True)

for metric in ["MAE(mean)", "RMSE(mean)", "R2(mean)"]:
    fig, ax = plt.subplots(figsize=(8,4))
    ax.bar(res_plot["model"], res_plot[metric])
    ax.set_title(f"Cross-Validated {metric} by Model")
    ax.set_xlabel("Model")
    ax.set_ylabel(metric)
    plt.xticks(rotation=20, ha="right")
    fig.tight_layout()

    out_path = os.path.join(out_dir, metric.replace("(", "_").replace(")", "").replace("/", "_") + ".png")
    fig.savefig(out_path, dpi=200, bbox_inches="tight")
    plt.show()
    plt.close(fig)

print("Saved to:", out_dir)




